File uploading.
  -> upload file via http (
    - размер файла блокирует загрузку всех остальных полей.
    - создает нагрузку на основной сервер.
    )
  -> upload files coupling with other data / entity properties (
    - блокирует остальные поля (запись не будет создана до тех пор, пока не загрузится фотография).
    )
  -> validation formats, size and other rules (
    - требует затрат по времени.
    - могут быть нюансы, подводные камни.
  )
  [solving]:
    + запись создается отдельно.
    + загрузку файлов происходит через отдельный эндпоинт / метод.
    + сначала создается запись к которой асинхронно/в очереди подгружается фото.
    + то есть в метод на загрузку фото передается id созданной записи?.
    + что если после создания записи она будет удалена/модифицирована и т.д.

  -> compression, optimized formats for specific browsers and devices. Scaling. Placeholder. (
    - предыдущие минусы.
    - скорость самого алгоритма сжатия.
  )  [solving]: 
      + выделение микросервисов с единственной задачей по сжатию изображения, подгону по формату (мобилка, десктоп). 
      + можно масштабировать, распределять нагрузку, приоритет.

  -> link file path to record from DB (
    - если не удалось создать запись, делаем откат(удаляем) изображение?
        теряем проделанную работу на пред. шагах. 
    - нужно подчищать старые файлы, если соотв. запись удалена.
    - что если расположение файлов поменяется?
  )
    [solving]:
      + отдельный сервис проверяет наличие записи, её photoUrl.
      + в случае повторного создания записи, пред. фото не удаляем какое-то время, а пытаемся предугадать тот же самый это файл или нет (по имени, размеру и др. параметры). На клиентской стороне спрашиваем хочет ли он загрузить тот же самый файл для продукта?.
      + предлагать галерею / существующие варианты фоток для предотв. повторной загрузки дублей.

  -> security (
    - как предотвратить доступ к изображениям для нежелательных лиц?
    - сохранение конф-и.
  )

-> централизованное хранение фото на основном сервере (потеря данных, много памяти, неоптимальное хранение).
  + s3 где решены все минусы пред. способа (дорого).
  + minio? то есть по сути отдельное место, где хранятся файлы.
-> как раздавать файлы наиболее быстро?
  + nginx - быстро работает со статикой, но имеет проблемы в виде расстояния до клиента, нагрузка.
    (Nginx предлагает множество возможностей для защиты статических файлов, таких как ограничение доступа, использование HTTPS и другие меры безопасности. Можно легко интегрировать с CDN, что позволяет глобально кэшировать статические файлы и ускорять доставку.)
  + cdn - распределенная система с наиболее быстрой доставкой
  + использование кеширования запросов.



=== FEATURES ===
  [] Pagination - разбиение списка данных [1,2,3,4,5] -> [[1,2], [3,4], [5]] / pages=2, limit=2 (count items per page). currpage=limit * (page - 1).
      request -> Q{limit:isNumber, page:isNumber}:DTO ->  
        
        - page -> {items: T[], meta: Meta}
        - meta (Meta) -> {page: num, limit: num, totalPagesCount: num, totalItemsCount: num, hasNextPage: bool, hasPrevPage: bool}